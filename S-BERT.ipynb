{"cells":[{"cell_type":"markdown","metadata":{"id":"tpvkGSSoH3rx"},"source":["# [Sentence-BERT](https://arxiv.org/pdf/1908.10084.pdf)\n","\n","[Reference Code](https://www.pinecone.io/learn/series/nlp/train-sentence-transformers-softmax/)"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"-QEAHJNNH3rz","executionInfo":{"status":"ok","timestamp":1740245468735,"user_tz":-420,"elapsed":16,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["import os\n","import math\n","import re\n","from   random import *\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import pickle\n","\n","# Set GPU device\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","\n","# os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n","# os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# device"]},{"cell_type":"code","execution_count":71,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1740245468739,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"qu-0z05pH3r0","outputId":"74ccc257-8f6c-4282-ec10-8fe49d1d0570"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":71}],"source":["# Set device MPS or Cuda\n","# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\")\n","# device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1342,"status":"ok","timestamp":1740245470082,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"0WFSFtolIaWP","outputId":"34452946-e970-437c-dde7-a39f001ed2c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# connect with google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# mount with os\n","import os\n","os.chdir('/content/drive/My Drive/_NLP/A4/NLP-A4-Do-You-Agree')"]},{"cell_type":"markdown","metadata":{"id":"xaS0nuiaH3r1"},"source":["## 1. Data"]},{"cell_type":"markdown","metadata":{"id":"iAnQ8KQBH3r1"},"source":["### Train, Test, Validation"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2272,"status":"ok","timestamp":1740245472355,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"1FuG3rORJEdj","outputId":"b2986518-6b75-4ef5-eb35-43c5673fd032"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]}],"source":["!pip install datasets"]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14636,"status":"ok","timestamp":1740245486992,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"gZoerj6dH3r1","outputId":"f987cb5a-f195-48bc-ee57-de008642b5fd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["({'premise': Value(dtype='string', id=None),\n","  'hypothesis': Value(dtype='string', id=None),\n","  'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None),\n","  'idx': Value(dtype='int32', id=None)},\n"," {'premise': Value(dtype='string', id=None),\n","  'hypothesis': Value(dtype='string', id=None),\n","  'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None)})"]},"metadata":{},"execution_count":74}],"source":["import datasets\n","snli = datasets.load_dataset('snli')\n","mnli = datasets.load_dataset('glue', 'mnli')\n","mnli['train'].features, snli['train'].features"]},{"cell_type":"code","execution_count":75,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1740245487002,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"smmLeMXuH3r1","outputId":"e39cda66-7f00-4d79-fb90-4c669a75ce88"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"]},"metadata":{},"execution_count":75}],"source":["# List of datasets to remove 'idx' column from\n","mnli.column_names.keys()"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"WS2GTq05H3r2","executionInfo":{"status":"ok","timestamp":1740245487010,"user_tz":-420,"elapsed":7,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# Remove 'idx' column from each dataset\n","for column_names in mnli.column_names.keys():\n","    mnli[column_names] = mnli[column_names].remove_columns('idx')"]},{"cell_type":"code","execution_count":77,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1740245487019,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"1tEpamYoH3r2","outputId":"e7e0ea7c-f4d4-49d0-d9b3-6645e92543c5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"]},"metadata":{},"execution_count":77}],"source":["mnli.column_names.keys()"]},{"cell_type":"code","execution_count":78,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294,"status":"ok","timestamp":1740245487442,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"EP5YIZ1qH3r3","outputId":"6185ea48-9d20-4862-83e7-046ef6267f74"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0, 1, 2]), array([-1,  0,  1,  2]))"]},"metadata":{},"execution_count":78}],"source":["import numpy as np\n","np.unique(mnli['train']['label']), np.unique(snli['train']['label'])\n","#snli also have -1"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"F1_xvKPyH3r3","executionInfo":{"status":"ok","timestamp":1740245487454,"user_tz":-420,"elapsed":11,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# there are -1 values in the label feature, these are where no class could be decided so we remove\n","snli = snli.filter(\n","    lambda x: 0 if x['label'] == -1 else 1\n",")"]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2828,"status":"ok","timestamp":1740245490468,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"AhPWd4SzH3r3","outputId":"af1a83f4-7768-43bc-af7c-2d75838a74a9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0, 1, 2]), array([0, 1, 2]))"]},"metadata":{},"execution_count":80}],"source":["import numpy as np\n","np.unique(mnli['train']['label']), np.unique(snli['train']['label'])\n","#snli also have -1"]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44,"status":"ok","timestamp":1740245490515,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"KJ5Ymq-QH3r3","outputId":"8e35d722-5f83-407a-b6b8-657c063f4821"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['premise', 'hypothesis', 'label'],\n","        num_rows: 1000\n","    })\n","    test: Dataset({\n","        features: ['premise', 'hypothesis', 'label'],\n","        num_rows: 100\n","    })\n","    validation: Dataset({\n","        features: ['premise', 'hypothesis', 'label'],\n","        num_rows: 1000\n","    })\n","})"]},"metadata":{},"execution_count":81}],"source":["# Assuming you have your two DatasetDict objects named snli and mnli\n","from datasets import DatasetDict\n","# Merge the two DatasetDict objects\n","raw_dataset = DatasetDict({\n","    'train': datasets.concatenate_datasets([snli['train'], mnli['train']]).shuffle(seed=55).select(list(range(1000))),\n","    'test': datasets.concatenate_datasets([snli['test'], mnli['test_mismatched']]).shuffle(seed=55).select(list(range(100))),\n","    'validation': datasets.concatenate_datasets([snli['validation'], mnli['validation_mismatched']]).shuffle(seed=55).select(list(range(1000)))\n","})\n","#remove .select(list(range(1000))) in order to use full dataset\n","# Now, merged_dataset_dict contains the combined datasets from snli and mnli\n","raw_dataset"]},{"cell_type":"markdown","metadata":{"id":"sKiRABXVH3r4"},"source":["## 2. Preprocessing"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"GUTguo9ReyML","executionInfo":{"status":"ok","timestamp":1740245490548,"user_tz":-420,"elapsed":30,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# import custom modules\n","from app.helpers.classes import BERT, SimpleTokenizer"]},{"cell_type":"code","execution_count":83,"metadata":{"id":"MHrf6IUBeao7","executionInfo":{"status":"ok","timestamp":1740245490553,"user_tz":-420,"elapsed":3,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["data = pickle.load(open('./app/models/bert-pretrained-data.pkl', 'rb'))\n","word2id = data['word2id']\n","max_len = data['max_len']\n","max_mask = data['max_mask']"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"ROGzVCsCeszK","executionInfo":{"status":"ok","timestamp":1740245490557,"user_tz":-420,"elapsed":3,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["#\n","tokenizer = SimpleTokenizer(word2id)"]},{"cell_type":"code","execution_count":85,"metadata":{"id":"sZXgmxCPH3r5","executionInfo":{"status":"ok","timestamp":1740245491073,"user_tz":-420,"elapsed":515,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["def preprocess_function(examples):\n","    # Tokenize the premise\n","    premise_result = tokenizer.encode(\n","        examples['premise'])\n","    #num_rows, max_seq_length\n","    # Tokenize the hypothesis\n","    hypothesis_result = tokenizer.encode(\n","        examples['hypothesis'])\n","    #num_rows, max_seq_length\n","    # Extract labels\n","    labels = examples[\"label\"]\n","    #num_rows\n","    return {\n","        \"premise_input_ids\": premise_result[\"input_ids\"],\n","        \"premise_attention_mask\": premise_result[\"attention_mask\"],\n","        \"hypothesis_input_ids\": hypothesis_result[\"input_ids\"],\n","        \"hypothesis_attention_mask\": hypothesis_result[\"attention_mask\"],\n","        \"labels\" : labels\n","    }\n","\n","tokenized_datasets = raw_dataset.map(\n","    preprocess_function,\n","    batched=True,\n",")\n","\n","tokenized_datasets = tokenized_datasets.remove_columns(['premise','hypothesis','label'])\n","tokenized_datasets.set_format(\"torch\")"]},{"cell_type":"code","execution_count":86,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1740245491077,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"ccDehWgtH3r5","outputId":"1f0a10d0-d601-407c-e4c3-c110df7a3d7a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n","        num_rows: 1000\n","    })\n","    test: Dataset({\n","        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n","        num_rows: 100\n","    })\n","    validation: Dataset({\n","        features: ['premise_input_ids', 'premise_attention_mask', 'hypothesis_input_ids', 'hypothesis_attention_mask', 'labels'],\n","        num_rows: 1000\n","    })\n","})"]},"metadata":{},"execution_count":86}],"source":["tokenized_datasets"]},{"cell_type":"markdown","metadata":{"id":"h01CljtVH3r5"},"source":["## 3. Data loader"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"vQUY1FcgH3r5","executionInfo":{"status":"ok","timestamp":1740245491080,"user_tz":-420,"elapsed":2,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","# initialize the dataloader\n","batch_size = 32\n","train_dataloader = DataLoader(\n","    tokenized_datasets['train'],\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","eval_dataloader = DataLoader(\n","    tokenized_datasets['validation'],\n","    batch_size=batch_size\n",")\n","test_dataloader = DataLoader(\n","    tokenized_datasets['test'],\n","    batch_size=batch_size\n",")"]},{"cell_type":"code","execution_count":88,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1740245491085,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"I5fyOrxDH3r5","outputId":"cd317fd2-7d36-4767-d630-2c33ff3a1521"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 1000])\n","torch.Size([32, 1000])\n","torch.Size([32, 1000])\n","torch.Size([32, 1000])\n","torch.Size([32])\n"]}],"source":["for batch in train_dataloader:\n","    print(batch['premise_input_ids'].shape)\n","    print(batch['premise_attention_mask'].shape)\n","    print(batch['hypothesis_input_ids'].shape)\n","    print(batch['hypothesis_attention_mask'].shape)\n","    print(batch['labels'].shape)\n","    break"]},{"cell_type":"markdown","metadata":{"id":"FtfzB4YgH3r5"},"source":["## 4. Model"]},{"cell_type":"code","execution_count":89,"metadata":{"id":"36P7RhEY42lF","executionInfo":{"status":"ok","timestamp":1740245491086,"user_tz":-420,"elapsed":1,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["#from app.helpers.classes import BERT, Embedding  # Now the import should work"]},{"cell_type":"code","execution_count":90,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":683,"status":"ok","timestamp":1740245491771,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"T2sAWsM2m8Kq","outputId":"79224369-64ef-4d71-869a-8fb202eb1255"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-90-a0a3fa9658ba>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  state_dict = torch.load(save_path)\n"]},{"output_type":"execute_result","data":{"text/plain":["BERT(\n","  (embedding): Embedding(\n","    (tok_embed): Embedding(23069, 768)\n","    (pos_embed): Embedding(1000, 768)\n","    (seg_embed): Embedding(2, 768)\n","    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (layers): ModuleList(\n","    (0-5): 6 x MultiHeadAttention(\n","      (W_Q): Linear(in_features=768, out_features=512, bias=True)\n","      (W_K): Linear(in_features=768, out_features=512, bias=True)\n","      (W_V): Linear(in_features=768, out_features=512, bias=True)\n","    )\n","  )\n","  (fc): Linear(in_features=768, out_features=768, bias=True)\n","  (activ): Tanh()\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  (decoder): Linear(in_features=768, out_features=23069, bias=False)\n",")"]},"metadata":{},"execution_count":90}],"source":["# save_path = f'./app/models/bert-pretrained-model.pt'\n","# model = BERT()\n","# model.load_state_dict(torch.load(save_path))\n","# model.to(device)\n","\n","save_path = f'./app/models/bert-pretrained-model.pt'\n","model = BERT()\n","\n","# Load the state dictionary with strict=False\n","state_dict = torch.load(save_path)\n","model.load_state_dict(state_dict, strict=False)\n","\n","model.to(device)\n","\n","# checkpoint = torch.load(save_path, map_location=\"cpu\")\n","# print(\"Keys in checkpoint:\", checkpoint.keys())"]},{"cell_type":"markdown","metadata":{"id":"oq0FHqBFH3r5"},"source":["### Pooling\n","SBERT adds a pooling operation to the output of BERT / RoBERTa to derive a fixed sized sentence embedding"]},{"cell_type":"code","execution_count":91,"metadata":{"id":"kdRvcswSH3r5","executionInfo":{"status":"ok","timestamp":1740245491776,"user_tz":-420,"elapsed":3,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# define mean pooling function\n","def mean_pool(token_embeds, attention_mask):\n","    # reshape attention_mask to cover 768-dimension embeddings\n","    in_mask = attention_mask.unsqueeze(-1).expand(\n","        token_embeds.size()\n","    ).float()\n","    # perform mean-pooling but exclude padding tokens (specified by in_mask)\n","    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(\n","        in_mask.sum(1), min=1e-9\n","    )\n","    return pool"]},{"cell_type":"markdown","metadata":{"id":"y0zzOKCZH3r5"},"source":["## 5. Loss Function\n","\n","## Classification Objective Function\n","We concatenate the sentence embeddings $u$ and $v$ with the element-wise difference  $\\lvert u - v \\rvert $ and multiply the result with the trainable weight  $ W_t âˆˆ  \\mathbb{R}^{3n \\times k}  $:\n","\n","$ o = \\text{softmax}\\left(W^T \\cdot \\left(u, v, \\lvert u - v \\rvert\\right)\\right) $\n","\n","where $n$ is the dimension of the sentence embeddings and k the number of labels. We optimize cross-entropy loss. This structure is depicted in Figure 1.\n","\n","## Regression Objective Function.\n","The cosine similarity between the two sentence embeddings $u$ and $v$ is computed (Figure 2). We use means quared-error loss as the objective function.\n","\n","(Manhatten / Euclidean distance, semantically  similar sentences can be found.)"]},{"cell_type":"code","execution_count":92,"metadata":{"id":"cv3JcVMIH3r5","executionInfo":{"status":"ok","timestamp":1740245491786,"user_tz":-420,"elapsed":1,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["def configurations(u,v):\n","    # build the |u-v| tensor\n","    uv = torch.sub(u, v)   # batch_size,hidden_dim\n","    uv_abs = torch.abs(uv) # batch_size,hidden_dim\n","\n","    # concatenate u, v, |u-v|\n","    x = torch.cat([u, v, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n","    return x\n","\n","def cosine_similarity(u, v):\n","    dot_product = np.dot(u, v)\n","    norm_u = np.linalg.norm(u)\n","    norm_v = np.linalg.norm(v)\n","    similarity = dot_product / (norm_u * norm_v)\n","    return similarity"]},{"cell_type":"code","execution_count":93,"metadata":{"id":"aPRRJTG2H3r6","executionInfo":{"status":"ok","timestamp":1740245491801,"user_tz":-420,"elapsed":10,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["classifier_head = torch.nn.Linear(768*3, 3).to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n","optimizer_classifier = torch.optim.Adam(classifier_head.parameters(), lr=2e-5)\n","\n","criterion = nn.CrossEntropyLoss()"]},{"cell_type":"code","execution_count":94,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1740245491803,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"XG_UFXSfH3r6"},"outputs":[],"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# and setup a warmup for the first ~10% steps\n","total_steps = int(len(raw_dataset) / batch_size)\n","warmup_steps = int(0.1 * total_steps)\n","scheduler = get_linear_schedule_with_warmup(\n","\t\toptimizer, num_warmup_steps=warmup_steps,\n","  \tnum_training_steps=total_steps - warmup_steps\n",")\n","\n","# then during the training loop we update the scheduler per step\n","scheduler.step()\n","\n","scheduler_classifier = get_linear_schedule_with_warmup(\n","\t\toptimizer_classifier, num_warmup_steps=warmup_steps,\n","  \tnum_training_steps=total_steps - warmup_steps\n",")\n","\n","# then during the training loop we update the scheduler per step\n","scheduler_classifier.step()"]},{"cell_type":"code","execution_count":95,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1740245491819,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"Kz2ZorS4qfKb","outputId":"df198835-cba7-4e1a-e7e6-3eab40513d9c"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'input_ids': [tensor([4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), tensor([4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])], 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]}\n"]}],"source":["tokenizer = SimpleTokenizer({'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3, '[UNK]': 4})\n","output = tokenizer.encode([\"I love you\", \"I hate you\"])\n","print(output)"]},{"cell_type":"code","execution_count":96,"metadata":{"id":"40tG7dcIqikJ","executionInfo":{"status":"ok","timestamp":1740245491824,"user_tz":-420,"elapsed":4,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# import torch.nn as nn\n","\n","# vocab_size = len(tokenizer.word2id)  # Ensure correct size\n","# embedding_dim = 128\n","# embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=tokenizer.word2id['[PAD]'])"]},{"cell_type":"code","execution_count":97,"metadata":{"id":"tdCDsyT_qkmn","executionInfo":{"status":"ok","timestamp":1740245491825,"user_tz":-420,"elapsed":0,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["# vocab_size = len(tokenizer.word2id)  # Ensure correct vocab size\n","\n","# print(\"Inputs (Before Model Call):\")\n","# print(f\"Input IDs: {inputs_ids_a}\")\n","# print(f\"Max ID in Inputs: {inputs_ids_a.max()}, Min ID: {inputs_ids_a.min()}\")\n","# print(f\"Vocab Size: {vocab_size}\")\n","\n","# # Check if any value is out of bounds\n","# if inputs_ids_a.max() >= vocab_size or inputs_ids_a.min() < 0:\n","#     raise ValueError(\"Error: Token index out of bounds!\")\n","\n","# # Run the model\n","# u, _, _ = model(inputs_ids_a, segment_ids, masked_pos)\n"]},{"cell_type":"markdown","metadata":{"id":"pkt88NnlH3r6"},"source":["## 6. Training"]},{"cell_type":"code","execution_count":98,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["f9fd97174dbc4c2d92f19e6b2b4fff4a","386fbd5359e64561b9c7e83fd46472d6","6b295a226d96470db56e8a8056e43844","2047345e7c7840eb8e3381677cf6949e","8f22a20661884a328bd6e8188de96282","52cafeb8c4e74d84857e7ff46a72cb01","6d3378c51b464f28835fb23386e332b1","7ecb53a34c6043e4b84c07a56fdfb5ee","a4cc564d01674b3d8571cb04826712b9","d078478cfcc04c39b65cc22a387dc5bf","122e0eb48a7440f0adc32e8e2952601b"]},"executionInfo":{"elapsed":67182,"status":"ok","timestamp":1740245559020,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"N3lX7CuL5eei","outputId":"149e2135-fc2d-4d8c-ce25-4c87b9a297fe"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/167 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9fd97174dbc4c2d92f19e6b2b4fff4a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1 | loss = 1.102627 | Accuracy = 31.7%\n"]}],"source":["from tqdm.auto import tqdm\n","\n","num_epoch = 1\n","\n","# Reduced batch size\n","batch_size = 6\n","max_len = 1000\n","\n","# Recreate dataloaders with the new batch size\n","train_dataloader = DataLoader(\n","    tokenized_datasets['train'],\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","eval_dataloader = DataLoader(\n","    tokenized_datasets['validation'],\n","    batch_size=batch_size\n",")\n","test_dataloader = DataLoader(\n","    tokenized_datasets['test'],\n","    batch_size=batch_size\n",")\n","\n","# need segment and masked for model input but not used in SBERT\n","# Create segment_ids tensor with shape (batch_size, max_len)\n","#segment_ids = torch.tensor([0] * max_len).unsqueeze(0).repeat(batch_size, 1).to(device)\n","\n","# Create masked_pos tensor with shape (batch_size, max_mask)\n","#masked_pos = torch.tensor([0] * max_mask).unsqueeze(0).repeat(batch_size, 1).to(device)\n","\n","accuracy = 0\n","count = 0\n","# 1 epoch should be enough, increase if wanted\n","for epoch in range(num_epoch):\n","    model.train()\n","    classifier_head.train()\n","    # initialize the dataloader loop with tqdm (tqdm == progress bar)\n","    for step, batch in enumerate(tqdm(train_dataloader, leave=True)):\n","        # zero all gradients on each new step\n","        optimizer.zero_grad()\n","        optimizer_classifier.zero_grad()\n","\n","        # prepare batches and more all to the active device\n","        inputs_ids_a = batch['premise_input_ids'].to(device)\n","        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n","        attention_a = batch['premise_attention_mask'].to(device)\n","        attention_b = batch['hypothesis_attention_mask'].to(device)\n","        label = batch['labels'].to(device)\n","\n","        # Truncate input sequences to the new max length\n","        inputs_ids_a = inputs_ids_a[:, :max_len]\n","        inputs_ids_b = inputs_ids_b[:, :max_len]\n","        attention_a = attention_a[:, :max_len]\n","        attention_b = attention_b[:, :max_len]\n","\n","        current_batch_size = inputs_ids_a.shape[0]\n","        # Create segment_ids tensor with shape (batch_size, max_len) for the current batch\n","        segment_ids = torch.tensor([0] * max_len).unsqueeze(0).repeat(current_batch_size, 1).to(device)\n","\n","        # Create masked_pos tensor with shape (batch_size, max_mask) for the current batch\n","        masked_pos = torch.tensor([0] * max_mask).unsqueeze(0).repeat(current_batch_size, 1).to(device)\n","\n","        # extract token embeddings from BERT at last_hidden_state\n","        u, _, _ = model(inputs_ids_a, segment_ids[:, :max_len], masked_pos)\n","        v, _, _ = model(inputs_ids_b, segment_ids[:, :max_len], masked_pos)\n","\n","        u_last_hidden_state = u # all token embeddings A = batch_size, seq_len, hidden_dim\n","        v_last_hidden_state = v # all token embeddings B = batch_size, seq_len, hidden_dim\n","\n","         # get the mean pooled vectors\n","        u_mean_pool = mean_pool(u_last_hidden_state, attention_a) # batch_size, hidden_dim\n","        v_mean_pool = mean_pool(v_last_hidden_state, attention_b) # batch_size, hidden_dim\n","\n","        # build the |u-v| tensor\n","        uv = torch.sub(u_mean_pool, v_mean_pool)   # batch_size,hidden_dim\n","        uv_abs = torch.abs(uv) # batch_size,hidden_dim\n","\n","        # concatenate u, v, |u-v|\n","        x = torch.cat([u_mean_pool, v_mean_pool, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n","\n","        # process concatenated tensor through classifier_head\n","        x = classifier_head(x) #batch_size, classifer\n","        for out, lab in zip(x, label):\n","            count = count + 1\n","            if torch.argmax(out).item() == lab.item():\n","                accuracy = accuracy + 1\n","        # calculate the 'softmax-loss' between predicted and true label\n","        loss = criterion(x, label)\n","\n","        # using loss, calculate gradients and then optimizerize\n","        loss.backward()\n","        optimizer.step()\n","        optimizer_classifier.step()\n","\n","        scheduler.step() # update learning rate scheduler\n","        scheduler_classifier.step()\n","\n","    print(f'Epoch: {epoch + 1} | loss = {loss.item():.6f} | Accuracy = {(accuracy / count) * 100}%')"]},{"cell_type":"code","source":["model.eval()\n","classifier_head.eval()\n","\n","total_similarity = 0\n","num_batches = len(eval_dataloader)\n","\n","with torch.no_grad():\n","    for step, batch in enumerate(eval_dataloader):\n","        # Move all batch tensors to the active device\n","        inputs_ids_a = batch['premise_input_ids'].to(device)[:, :max_len]  # Truncate to max_len\n","        inputs_ids_b = batch['hypothesis_input_ids'].to(device)[:, :max_len]\n","        attention_a = batch['premise_attention_mask'].to(device)[:, :max_len]\n","        attention_b = batch['hypothesis_attention_mask'].to(device)[:, :max_len]\n","        labels = batch['labels'].to(device)\n","\n","        # Get the current batch size\n","        batch_size = inputs_ids_a.shape[0]\n","\n","        # Create segment_ids and masked_pos tensors with correct batch shape\n","        segment_ids = torch.zeros((batch_size, max_len), dtype=torch.long, device=device)\n","        masked_pos = torch.zeros((batch_size, max_mask), dtype=torch.long, device=device)\n","\n","        # Extract token embeddings from BERT\n","        u, _, _ = model(inputs_ids_a, segment_ids, masked_pos)  # (batch_size, seq_len, hidden_dim)\n","        v, _, _ = model(inputs_ids_b, segment_ids, masked_pos)\n","\n","        # Mean pooling for sentence embeddings\n","        u_mean = mean_pool(u, attention_a).detach().cpu().numpy()  # (batch_size, hidden_dim)\n","        v_mean = mean_pool(v, attention_b).detach().cpu().numpy()\n","\n","        # Compute cosine similarity for each sentence pair in the batch\n","        similarity_scores = [cosine_similarity(u_mean[i], v_mean[i]) for i in range(batch_size)]\n","\n","        # Compute average similarity for the batch\n","        batch_similarity = np.mean(similarity_scores)\n","        total_similarity += batch_similarity\n","\n","# Compute the final average similarity score\n","average_similarity = total_similarity / num_batches\n","print(f\"Average Cosine Similarity: {average_similarity:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GYZR0PRrsB9P","executionInfo":{"status":"ok","timestamp":1740245587472,"user_tz":-420,"elapsed":28447,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"5eb9e4cd-8c72-4417-9eef-0fceaf769d34"},"execution_count":99,"outputs":[{"output_type":"stream","name":"stdout","text":["Average Cosine Similarity: 0.6256\n"]}]},{"cell_type":"code","execution_count":100,"metadata":{"id":"2yNY8C0y8SWI","executionInfo":{"status":"ok","timestamp":1740245587834,"user_tz":-420,"elapsed":365,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}}},"outputs":[],"source":["save_path = f'./app/models/sentence_model.pt'\n","torch.save(model.state_dict(), save_path)"]},{"cell_type":"markdown","metadata":{"id":"CsRPIx1zH3r6"},"source":["## 7. Inference"]},{"cell_type":"code","execution_count":101,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":598,"status":"ok","timestamp":1740245588438,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"},"user_tz":-420},"id":"p7U9tRWd8aVQ","outputId":"7b6ee768-5d7f-4765-f32f-145d7b5f0700"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-101-579a262c9612>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(save_path))\n"]},{"output_type":"execute_result","data":{"text/plain":["BERT(\n","  (embedding): Embedding(\n","    (tok_embed): Embedding(23069, 768)\n","    (pos_embed): Embedding(1000, 768)\n","    (seg_embed): Embedding(2, 768)\n","    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (layers): ModuleList(\n","    (0-5): 6 x MultiHeadAttention(\n","      (W_Q): Linear(in_features=768, out_features=512, bias=True)\n","      (W_K): Linear(in_features=768, out_features=512, bias=True)\n","      (W_V): Linear(in_features=768, out_features=512, bias=True)\n","    )\n","  )\n","  (fc): Linear(in_features=768, out_features=768, bias=True)\n","  (activ): Tanh()\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  (decoder): Linear(in_features=768, out_features=23069, bias=False)\n",")"]},"metadata":{},"execution_count":101}],"source":["save_path = f'./app/models/sentence_model.pt'\n","model = BERT()\n","model.load_state_dict(torch.load(save_path))\n","model.to(device)"]},{"cell_type":"code","execution_count":102,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7hrvtWPaqbU6","executionInfo":{"status":"ok","timestamp":1740245589484,"user_tz":-420,"elapsed":1044,"user":{"displayName":"Nyein Chan Aung","userId":"10271779707834005263"}},"outputId":"2d1e9841-6632-4dcb-bf6e-ad3457ef8c75"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cosine Similarity: 0.8057\n"]}],"source":["import torch\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","def mean_pooling(model_output, attention_mask):\n","    \"\"\"Perform mean pooling to get sentence embeddings\"\"\"\n","    token_embeddings = model_output.last_hidden_state  # (batch_size, seq_len, hidden_dim)\n","    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","    return torch.sum(token_embeddings * input_mask_expanded, 1) / input_mask_expanded.sum(1)\n","\n","def calculate_similarity(model, tokenizer, sentence_a, sentence_b, device):\n","    # Tokenize sentences with padding & truncation\n","    inputs_a = tokenizer(sentence_a, return_tensors='pt', truncation=True, padding='max_length', max_length=128).to(device)\n","    inputs_b = tokenizer(sentence_b, return_tensors='pt', truncation=True, padding='max_length', max_length=128).to(device)\n","\n","    # Extract token embeddings from BERT\n","    with torch.no_grad():  # Disable gradient calculations\n","        output_a = model(**inputs_a)\n","        output_b = model(**inputs_b)\n","\n","    # Apply mean pooling\n","    u = mean_pooling(output_a, inputs_a['attention_mask']).detach().cpu().numpy().reshape(-1)\n","    v = mean_pooling(output_b, inputs_b['attention_mask']).detach().cpu().numpy().reshape(-1)\n","\n","    # Compute cosine similarity\n","    similarity_score = cosine_similarity(u.reshape(1, -1), v.reshape(1, -1))[0, 0]\n","\n","    return similarity_score\n","\n","# Example usage\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load a pre-trained BERT model & tokenizer (e.g., BERT-base-uncased from Hugging Face)\n","from transformers import BertTokenizer, BertModel\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n","\n","# Define sentences\n","sentence_a = \"Your contribution helped make it possible for us to provide our students with a quality education.\"\n","sentence_b = \"Your contributions were of no help with our students' education.\"\n","\n","# Compute similarity\n","similarity = calculate_similarity(model, tokenizer, sentence_a, sentence_b, device)\n","print(f\"Cosine Similarity: {similarity:.4f}\")\n",""]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"pytorch_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.16"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f9fd97174dbc4c2d92f19e6b2b4fff4a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_386fbd5359e64561b9c7e83fd46472d6","IPY_MODEL_6b295a226d96470db56e8a8056e43844","IPY_MODEL_2047345e7c7840eb8e3381677cf6949e"],"layout":"IPY_MODEL_8f22a20661884a328bd6e8188de96282"}},"386fbd5359e64561b9c7e83fd46472d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52cafeb8c4e74d84857e7ff46a72cb01","placeholder":"â€‹","style":"IPY_MODEL_6d3378c51b464f28835fb23386e332b1","value":"100%"}},"6b295a226d96470db56e8a8056e43844":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ecb53a34c6043e4b84c07a56fdfb5ee","max":167,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4cc564d01674b3d8571cb04826712b9","value":167}},"2047345e7c7840eb8e3381677cf6949e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d078478cfcc04c39b65cc22a387dc5bf","placeholder":"â€‹","style":"IPY_MODEL_122e0eb48a7440f0adc32e8e2952601b","value":"â€‡167/167â€‡[01:07&lt;00:00,â€‡â€‡2.57it/s]"}},"8f22a20661884a328bd6e8188de96282":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52cafeb8c4e74d84857e7ff46a72cb01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d3378c51b464f28835fb23386e332b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ecb53a34c6043e4b84c07a56fdfb5ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4cc564d01674b3d8571cb04826712b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d078478cfcc04c39b65cc22a387dc5bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"122e0eb48a7440f0adc32e8e2952601b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}